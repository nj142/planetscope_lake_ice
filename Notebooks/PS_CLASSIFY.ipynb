{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 0: Imports\n",
    "import os, sys\n",
    "import glob\n",
    "import time\n",
    "import yaml\n",
    "import requests\n",
    "import time\n",
    "import zipfile\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import backoff\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Scripts\")))\n",
    "\n",
    "from clip_ALPOD_to_SR_extent import clip_vector_with_geometry, extract_geospatial_info_from_xml\n",
    "from mask_clouds_and_classify_ice import calculate_output_rasters\n",
    "from calculate_ice_cover_statistics_per_lake import calculate_lake_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1: Config for lake classification\n",
    "\n",
    "config = {\n",
    "    #UDM mask bands to remove data beneath\n",
    "    'udm_mask_bands': [3, 4, 5, 6], # 3 - Shadow, 4 - Light Haze, 5 - Heavy Haze (Depracated but kept in case any are UDM 2.0), 6 - Cloud\n",
    "   \n",
    "    #SR image bands to keep in the final TIF files\n",
    "    'sr_keep_bands': [3], #3 - Red\n",
    "\n",
    "    'pixel_reflectance_thresholds': {\n",
    "        'Ice': (950, 3800),  # Could change to 1100-- silty problem persists\n",
    "        'Snow': (3800, float('inf')),\n",
    "        'Water': (float('-inf'), 950)\n",
    "    }\n",
    "}\n",
    "\n",
    "study_sites_to_process = {\n",
    "    'YKD': [\n",
    "        r\"D:\\planetscope_lake_ice\\Data\\Input\\YKD 5x5 km\\Breakup_2022\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "output_path = r\"D:\\planetscope_lake_ice\\Data\\Output\"\n",
    "\n",
    "alpod_vector_shapefiles = {\n",
    "    'YKD': r\"D:\\planetscope_lake_ice\\Data\\Input\\alpod5x5ykd.shp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Image Processing Function \n",
    "\n",
    "def process_planetscope_image(sr_image_path, study_site, lake_vector_shapefile):\n",
    "    \"\"\"\n",
    "    For the given PlanetScope SR TIFF:\n",
    "      0) build output folders, and find its accompanying UDM & XML\n",
    "      1) delete everything but sr_keep_band to reduce size of TIFs in deep storage, create cloud mask as uint 8 file, create classified mask as a uint8 file\n",
    "      2) mask red band, threshold/classify ice & snow\n",
    "      3) append lake stats to NetCDF\n",
    "    \"\"\"\n",
    "    \n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    # 0: Create output folders // find correlated XML & UDM for this SR image\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    # build image name strings for processing dates\n",
    "    sr_filename = os.path.basename(sr_image_path) # E.g. 20200415_222212_87_1060_ortho_analytic_4b_sr.tif\n",
    "    sr_filename_no_ext = os.path.splitext(sr_filename)[0] # E.g. 20200415_222212_87_1060_ortho_analytic_4b_sr\n",
    "    image_core_name = sr_filename_no_ext.split('_ortho', 1)[0] ## E.g. 20200415_222212_87_1060\n",
    "\n",
    "    # Get the full directory path where the SR image is located\n",
    "    sr_image_directory = os.path.dirname(sr_image_path)\n",
    "    \n",
    "    # identify the current season folder (e.g. \"Breakup_2019\") and build output paths based on that season\n",
    "    input_season_folder = os.path.basename(sr_image_directory) # e.g. \"Breakup_2019 from downloads - read from global config\"\n",
    "    output_rasters_dir = os.path.join(output_path, \"Rasters\", input_season_folder) \n",
    "    output_shapefile_dir = os.path.join(output_path, \"Shapefiles\", input_season_folder, sr_filename_no_ext)\n",
    "    for d in (output_rasters_dir, output_shapefile_dir): \n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    # locate UDM and XML metadata using glob to find matching files in the same directory\n",
    "    udm_pattern = os.path.join(sr_image_directory, f\"{image_core_name}*udm2.tif\")\n",
    "    xml_pattern = os.path.join(sr_image_directory, f\"{image_core_name}*.xml\")\n",
    "    \n",
    "    udm_files = glob.glob(udm_pattern)\n",
    "    xml_files = glob.glob(xml_pattern)\n",
    "    \n",
    "    if not udm_files or not xml_files:\n",
    "        raise FileNotFoundError(f\"\\n######################\\nERROR: UDM or XML files not found for {sr_filename}\\nLooked for UDM: {udm_pattern}\\nLooked for XML: {xml_pattern}\\n######################\\n\")\n",
    "    \n",
    "    udm_path = udm_files[0]  # Take the first match\n",
    "    xml_path = xml_files[0]  # Take the first match\n",
    "\n",
    "    print(f\"All pre-processing complete. Beginning classification for image {sr_filename}.\\n\")\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    # 1: Clip study site lake mask to the image footprint (sourced from the XML file) so only lakes\n",
    "    #  which fall entirely within this SR image's extent are considered\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    output_vector_path = os.path.join(output_shapefile_dir, f\"{image_core_name}_lakes.shp\") # The lakes which fall within the image's extent\n",
    "\n",
    "    print(\"Clipping geometry...\")\n",
    "    geo_info = extract_geospatial_info_from_xml(xml_path)\n",
    "\n",
    "    clip_vector_with_geometry(\n",
    "        lake_vector_shapefile,\n",
    "        geo_info['geometry'],\n",
    "        output_vector_path\n",
    "    )\n",
    "\n",
    "    print(\"Geometry clipped successfully.\\n\")\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    # 2: Delete everything but sr_keep_band to reduce size of TIFs in deep storage, create cloud mask as uint 8 file, create classified mask as a uint8 file, all with lzw compression\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "    output_sr_path = os.path.join(output_rasters_dir, \"Single_Band_Rasters_Uint16\", sr_filename)\n",
    "    output_udm_path = os.path.join(output_rasters_dir, \"Cloud_Masks_Uint8\", f\"{image_core_name}_cloud_mask.tif\")\n",
    "    output_classified_path = os.path.join(output_rasters_dir, \"Ice_Snow_Water_Classified_Masks_Uint8\", f\"{image_core_name}_classified_ice_snow.tif\")\n",
    "    \n",
    "    # Make sure the subdirectories exist\n",
    "    for subdir_path in [os.path.dirname(output_sr_path), os.path.dirname(output_udm_path), os.path.dirname(output_classified_path)]:\n",
    "        os.makedirs(subdir_path, exist_ok=True)\n",
    "    \n",
    "    print(\"Creating cloud mask, clipping rasters...\")\n",
    "    calculate_output_rasters(\n",
    "        sr_image_path,\n",
    "        udm_path,\n",
    "        config['udm_mask_bands'],  # Fixed: was 'mask_bands', should be 'udm_mask_bands'\n",
    "        config['sr_keep_bands'],   # Fixed: was 'keep_bands', should be 'sr_keep_bands'\n",
    "        output_sr_path,\n",
    "        output_udm_path,\n",
    "        output_classified_path\n",
    "    )\n",
    "\n",
    "    print(f\"     Clouds masked successfully.\")\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "    # 3: Calculate statistics for each lake, and then add the statistics to an excel sheet\n",
    "    # ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "    print(f\"Calculating lake statistics...\")\n",
    "    calculate_lake_statistics(\n",
    "        output_classified_path,\n",
    "        image_core_name,\n",
    "        output_path,\n",
    "        study_site,\n",
    "        lake_vector_shapefile\n",
    "    )\n",
    "\n",
    "    print(f\"Finished processing {image_core_name}\\n# ──────────────────────────────────────────────────────────────────────────────── #\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pre-processing complete. Beginning classification for image 20220419_211221_04_2440_ortho_analytic_4b_sr.tif.\n",
      "\n",
      "Clipping geometry...\n",
      "     Extracted polygon with 5 vertices\n",
      "     Output shapefile contains 1 lakes\n",
      "Geometry clipped successfully.\n",
      "\n",
      "Creating cloud mask, clipping rasters...\n",
      "Loading raster data with Dask...\n",
      "Creating single red band raster...\n"
     ]
    }
   ],
   "source": [
    "# Block 3: Loop through all images to clip, clean, and classify lake ice cover\n",
    "\n",
    "for study_site, paths_list in study_sites_to_process.items():\n",
    "    lake_vector_shapefile = alpod_vector_shapefiles[study_site]  # Get corresponding shapefile\n",
    "\n",
    "    for site_folder in paths_list:\n",
    "        pattern = os.path.join(site_folder, \"*.tif\")  # Match all .tif files\n",
    "        for sr_tif_path in glob.glob(pattern):\n",
    "            if 'udm' not in os.path.basename(sr_tif_path).lower():  # Exclude files with 'udm' so only SR goes through\n",
    "                try:\n",
    "                    # Fixed: Corrected function call with proper arguments\n",
    "                    process_planetscope_image(sr_tif_path, study_site, lake_vector_shapefile)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {sr_tif_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
