{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 0: Imports\n",
    "import os, sys\n",
    "import glob\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\", \"Scripts\")))\n",
    "\n",
    "from clip_ALPOD_to_SR_extent import clip_vector_with_geometry, extract_geospatial_info_from_json\n",
    "from mask_clouds_and_classify_ice import create_mask_rasters, classify_ice_cover\n",
    "from calculate_ice_cover_statistics_per_lake import calculate_lake_statistics, add_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1: Initialize Data directory & instructions for project setup / organization\n",
    "# !git clone https://github.com/nj142/planetscope_lake_ice\n",
    "# Create unclassified Data folder, with the option to retrain a model with new parameters?\n",
    "# List your batches and make a folder for input and output in both.\n",
    "# User drops their downloads into the input folder and then the code spits out the NetCDF and other stuff into output\n",
    "# Create NetCDF file with unlimited lakes dimension, etc?  For now don't need to do this, can just update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2 (ONLY IF RETRAINING): Convert downloaded PlanetScope RGB directories to RGB JPEGs to be labeled\n",
    "# Run tif-to-jpeg.py, then upload to labelbox.  \n",
    "# Once classified on labelbox, save to 3-Download Labelbox masks here, then run clip_PNG_label_data_to_tif.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Config for lake classification\n",
    "\n",
    "config = {\n",
    "    #UDM mask bands\n",
    "    'mask_bands': [3, 4, 6],\n",
    "    #SR image bands to keep in the final TIF files\n",
    "    'keep_bands': [3],\n",
    "    'thresholds': {\n",
    "        'Ice': (950, 3800),\n",
    "        'Snow': (3800, float('inf')),\n",
    "        'Water': (float('-inf'), 950)\n",
    "    },\n",
    "    'min_clear_percent': 30\n",
    "}\n",
    "    \n",
    "\n",
    "study_sites_to_process = {\n",
    "    'YKD': [r\"D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR.tif\",]\n",
    "}\n",
    "\n",
    "output_rasters_dir = r\"D:\\planetscope_lake_ice\\Data\\Output\\Rasters\"\n",
    "output_shapefiles_dir = r\"D:\\planetscope_lake_ice\\Data\\Output\\Shapefiles\"\n",
    "netcdf_path = r\"D:\\planetscope_lake_ice\\Data\\Output\\TEST_CDF.nc\"\n",
    "vector_path = r\"D:\\planetscope_lake_ice\\Data\\Input\\ALPOD\\ALPODlakes.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4: Function for classifying ice cover in a PlanetScope image (separated for code logic readability)\n",
    "\n",
    "def process_planetscope_image(planetscope_image_path, study_site):\n",
    "\n",
    "    # Find relevant folder for study site\n",
    "    site_rasters_dir = os.path.join(output_rasters_dir, study_site)\n",
    "    site_shapefiles_dir = os.path.join(output_shapefiles_dir, study_site)\n",
    "\n",
    "    # \"planetscope_image_basename\" is just the root name of each image w/ extension.  Used to find corresponding UDM mask for SR images\n",
    "    planetscope_image_basename = os.path.basename(planetscope_image_path)\n",
    "    # planetscope_image_name is just the basename with no file extension \n",
    "    image_name_parts = planetscope_image_basename.split('_')\n",
    "    planetscope_image_name = '_'.join(image_name_parts[:4])  # e.g., \"20240614_213553_65_242d\"\n",
    "\n",
    "    print(f\"Processing {planetscope_image_basename} from {study_site}\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 0. Find corresponding Planet's Usable Data Mask (UDM) and JSON for given SR image. \n",
    "    # ------------------------------------------------------------------------- \n",
    "\n",
    "    # Find corresponding UDM file\n",
    "    image_dir = os.path.dirname(planetscope_image_path)\n",
    "    \n",
    "    # Generate a pattern that matches UDM files\n",
    "    udm_pattern = os.path.join(image_dir, f\"{planetscope_image_name}*udm*.tif\")\n",
    "\n",
    "    # Use glob to find all matching files\n",
    "    matching_files = glob.glob(udm_pattern)\n",
    "    \n",
    "    if matching_files:\n",
    "        # If any matching files are found, return the first match\n",
    "        udm_path = matching_files[0]\n",
    "        print(f\"Found UDM file: {udm_path}\")\n",
    "    else:\n",
    "        print(f\"UDM file not found for {planetscope_image_basename}\")\n",
    "\n",
    "    # Split the filename on underscores and join the first four parts\n",
    "    json_name = f\"{planetscope_image_name}.json\"\n",
    "    json_path = os.path.join(os.path.dirname(planetscope_image_path), json_name)\n",
    "\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"Could not find JSON file: {json_path}\")\n",
    "        print(\"Checking directory contents for a valid JSON file...\")\n",
    "        \n",
    "        possible_jsons = [\n",
    "            f for f in os.listdir(os.path.dirname(planetscope_image_path))\n",
    "            if f.endswith('.json') and '_metadata' not in f\n",
    "        ]\n",
    "        \n",
    "        if possible_jsons:\n",
    "            json_path = os.path.join(os.path.dirname(planetscope_image_path), possible_jsons[0])\n",
    "            print(f\"Using fallback JSON file: {json_path}\")\n",
    "        else:\n",
    "            raise ValueError(f\"JSON file not found for {planetscope_image_basename}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. Clip the given large ALPOD vector dataset to just the SR image's extent.\n",
    "    #     Save the clipped vector to the clipped_vector_path.\n",
    "    # ------------------------------------------------------------------------- \n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"Clipping lakes to valid UDM data extent (excluding padded areas)...\")\n",
    "\n",
    "    # Make an output subfolder for each image (there are 4 files per shapefile, this keeps it organized)\n",
    "    img_subfolder = os.path.join(site_shapefiles_dir, os.path.splitext(planetscope_image_basename)[0])\n",
    "    os.makedirs(img_subfolder, exist_ok=True)\n",
    "    clipped_vector_path = os.path.join(img_subfolder, \"clipped.shp\")\n",
    "\n",
    "    # Get Planet geometry and projection metadata for quick calculations\n",
    "    geospatial_info = extract_geospatial_info_from_json(json_path)\n",
    "    geometry = geospatial_info['geometry']\n",
    "    print(f\"{geometry} is geometry\")\n",
    "    \n",
    "    #\"\"\"\n",
    "    # Use the UDM file to clip the vector to the SR image\n",
    "    features_kept = clip_vector_with_geometry(\n",
    "        vector_path,\n",
    "        geometry,\n",
    "        clipped_vector_path\n",
    "    )\n",
    "    #\"\"\"\n",
    "    end_time = time.time()\n",
    "    \"\"\"print(f\"Lakes kept: {features_kept} in {end_time - start_time} seconds\")\"\"\"\n",
    "    del start_time,end_time \n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. Mask out the haze/cloud/shadow layers (or whichever \"mask_bands\" are selected)\n",
    "    #      and save just the pixels from the red band (or whichever \"keep_bands\" are selected)\n",
    "    #      which are contained within the vector outlines from step 1, used like a cookie cutter.\n",
    "    # ------------------------------------------------------------------------- \n",
    "\n",
    "    # Want to try to change this so it works on a lake-by-lake basis.  Fill each rasterized\n",
    "    # pixel from the vector with its lake ID.  Then draw a minimum bounding box around all the pixels\n",
    "    # with that lake id.  save that as a new TIF.\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Removing unusable data...\")\n",
    "\n",
    "    # Create classified subdirectory to save the cloud and land-free satellite images to\n",
    "    site_masked_dir = os.path.join(site_rasters_dir, 'Masked Rasters')\n",
    "    os.makedirs(site_masked_dir, exist_ok=True)\n",
    "    masked_path = os.path.join(site_masked_dir, planetscope_image_basename)\n",
    "\n",
    "    site_lake_ids_dir = os.path.join(site_rasters_dir, 'Lake ID Rasters')\n",
    "    os.makedirs(site_lake_ids_dir, exist_ok=True)\n",
    "    lake_ids_path = os.path.join(site_lake_ids_dir, planetscope_image_basename)\n",
    "\n",
    "    #\"\"\"\n",
    "    #THIS IS CURRENTLY BROKEN BECAUSE THE POLYGON IS WRONGLY PLACED!!  NEED TO FIX\n",
    "    create_mask_rasters(\n",
    "        planetscope_image_path,\n",
    "        udm_path,\n",
    "        clipped_vector_path,\n",
    "        config['mask_bands'],\n",
    "        config['keep_bands'],\n",
    "        masked_path,\n",
    "        lake_ids_path\n",
    "    )\n",
    "    #\"\"\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Lake IDs raster mask saved to {lake_ids_path}\")\n",
    "    print(f\"Masked {', '.join(['band ' + str(b) for b in config['keep_bands']])} saved to {masked_path} in {end_time - start_time} seconds\")\n",
    "    del start_time,end_time\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3. Classify Ice, Snow, and Water (or whatever given classes are) using band\n",
    "    #     thresholding on the \"keep\" band.  (For our cases, this is red band thresholding.)\n",
    "    # ------------------------------------------------------------------------- \n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Classifying pixels...\")\n",
    "\n",
    "    # Create classified & lake ID raster subdirectory to save the ice/snow/water categorically classified rasters & lake id categorized rasters\n",
    "    site_classified_dir = os.path.join(site_rasters_dir, 'Classified Rasters')\n",
    "    os.makedirs(site_classified_dir, exist_ok=True)\n",
    "    classified_path = os.path.join(site_classified_dir, planetscope_image_basename)\n",
    "\n",
    "    #\"\"\"\n",
    "    classify_ice_cover(\n",
    "        masked_path,\n",
    "        config['thresholds'],\n",
    "        classified_path\n",
    "    )\n",
    "    #\"\"\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    class_labels = [f\"{i+1} = {name}\" for i, name in enumerate(config['thresholds'].keys())]\n",
    "    print(f\"Categorical classified ice mask saved with {', '.join(class_labels)} in {end_time - start_time} seconds\")\n",
    "    del start_time,end_time\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4. Calculate lake statistics for the lake, and save to the final NetCDF file.\n",
    "    # ------------------------------------------------------------------------- \n",
    "        \n",
    "    print(f\"\\nProcessing {planetscope_image_basename} for lake statistics...\")\n",
    "\n",
    "    # Calculate lake statistics using the updated function signature\n",
    "    calculate_lake_statistics(\n",
    "        lake_ids_path,\n",
    "        classified_path,\n",
    "        planetscope_image_name,\n",
    "        netcdf_path,\n",
    "        study_site,\n",
    "        vector_path,\n",
    "        config\n",
    "    )\n",
    "\n",
    "    print(f\"Lake statistics calculated and saved to netCDF file for {planetscope_image_basename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20190429_215112_103c_3B_AnalyticMS_SR.tif from YKD\n",
      "Found UDM file: D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c_3B_udm2.tif\n",
      "Could not find JSON file: D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c_3B.json\n",
      "Checking directory contents for a valid JSON file...\n",
      "Using fallback JSON file: D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c.json\n",
      "Clipping lakes to valid UDM data extent (excluding padded areas)...\n",
      "Reading JSON file: D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c.json\n",
      "Raw geometry from JSON: {\"coordinates\": [[[-163.5078022789682, 62.90750460876561], [-163.55876157160918, 62.835407254229935], [-163.07086430047738, 62.76315468832276], [-163.01962861270457, 62.83521893825884], [-163.5078022789682, 62.90750460876561]]], \"type\": \"Polygon\"}\n",
      "Number of coordinates in polygon: 5\n",
      "{'coordinates': [[[-163.5078022789682, 62.90750460876561], [-163.55876157160918, 62.835407254229935], [-163.07086430047738, 62.76315468832276], [-163.01962861270457, 62.83521893825884], [-163.5078022789682, 62.90750460876561]]], 'type': 'Polygon'} is geometry\n",
      "Clipping vector: D:\\planetscope_lake_ice\\Data\\Input\\ALPOD\\ALPODlakes.shp\n",
      "Using geometry: {\"coordinates\": [[[-163.5078022789682, 62.90750460876561], [-163.55876157160918, 62.835407254229935], [-163.07086430047738, 62.76315468832276], [-163.01962861270457, 62.83521893825884], [-163.5078022789682, 62.90750460876561]]], \"type\": \"Polygon\"}\n",
      "Output path: D:\\planetscope_lake_ice\\Data\\Output\\Shapefiles\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR\\clipped.shp\n",
      "Created OGR geometry: { \"type\": \"Polygon\", \"coordinates\": [ [ [ -163.5078022789682, 62.907504608765613 ], [ -163.558761571609182, 62.835407254229935 ], [ -163.070864300477382, 62.763154688322757 ], [ -163.019628612704565, 62.835218938258841 ], [ -163.5078022789682, 62.907504608765613 ] ] ] }\n",
      "Geometry is valid: True\n",
      "Footprint SRS (EPSG:4326): GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]\n",
      "Vector SRS: PROJCS[\"NAD83 / Alaska Albers\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Albers_Conic_Equal_Area\"],PARAMETER[\"latitude_of_center\",50],PARAMETER[\"longitude_of_center\",-154],PARAMETER[\"standard_parallel_1\",55],PARAMETER[\"standard_parallel_2\",65],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3338\"]]\n",
      "Vector EPSG code: 3338\n",
      "Transforming footprint from WGS84 to vector SRS...\n",
      "Transformed geometry: { \"type\": \"Polygon\", \"coordinates\": [ [ [ -480337.693127783655655, 1471874.320879712002352 ], [ -484050.28343321493594, 1464268.865922526456416 ], [ -460601.111522321065422, 1452802.007662368239835 ], [ -456924.885845662851352, 1460428.52665861370042 ], [ -480337.693127783655655, 1471874.320879712002352 ] ] ] }\n",
      "Geometry envelope after transform: (-484050.28343321494, -456924.88584566285, 1452802.0076623682, 1471874.320879712)\n",
      "Footprint WKT: POLYGON ((-480337.693127784 1471874.32087971,-484050.283433215 1464268.86592253,-460601.111522321 1452802.00766237,-456924.885845663 1460428.52665861,-480337.693127784 1471874.32087971))\n",
      "Creating temporary footprint shapefile: D:\\planetscope_lake_ice\\Data\\Output\\Shapefiles\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR\\temp_footprint.shp\n",
      "Running ogr2ogr with -clipsrc option...\n",
      "Command: ogr2ogr -f ESRI Shapefile D:\\planetscope_lake_ice\\Data\\Output\\Shapefiles\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR\\clipped.shp D:\\planetscope_lake_ice\\Data\\Input\\ALPOD\\ALPODlakes.shp -clipsrc D:\\planetscope_lake_ice\\Data\\Output\\Shapefiles\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR\\temp_footprint.shp -overwrite\n",
      "Features kept: 538\n",
      "Removing unusable data...\n",
      "\n",
      "Processing surface reflectance image: 20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Creating lake ID mask from: clipped.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nj142\\AppData\\Local\\anaconda3\\Lib\\site-packages\\rasterio\\features.py:336: ShapeSkipWarning: Invalid or empty shape None at index 537 will not be rasterized.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading cloud mask bands [3, 4, 6] from: 20190429_215112_103c_3B_udm2.tif\n",
      "Saved lake ID raster to: D:\\planetscope_lake_ice\\Data\\Output\\Rasters\\YKD\\Lake ID Rasters\\20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Applying combined lake and cloud mask to red band\n",
      "Saved masked band to: D:\\planetscope_lake_ice\\Data\\Output\\Rasters\\YKD\\Masked Rasters\\20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Lake IDs raster mask saved to D:\\planetscope_lake_ice\\Data\\Output\\Rasters\\YKD\\Lake ID Rasters\\20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Masked band 3 saved to D:\\planetscope_lake_ice\\Data\\Output\\Rasters\\YKD\\Masked Rasters\\20190429_215112_103c_3B_AnalyticMS_SR.tif in 64.24384045600891 seconds\n",
      "Classifying pixels...\n",
      "\n",
      "Classifying ice cover in: 20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Using classification scheme:\n",
      "  Ice: values from 950 to 3800\n",
      "  Snow: values from 3800 to inf\n",
      "  Water: values from -inf to 950\n",
      "Applying classification to valid pixels...\n",
      "Output classes:\n",
      "  Class 1: Ice\n",
      "  Class 2: Snow\n",
      "  Class 3: Water\n",
      "Saved classified raster to: D:\\planetscope_lake_ice\\Data\\Output\\Rasters\\YKD\\Classified Rasters\\20190429_215112_103c_3B_AnalyticMS_SR.tif\n",
      "Categorical classified ice mask saved with 1 = Ice, 2 = Snow, 3 = Water in 33.86732530593872 seconds\n",
      "\n",
      "Processing 20190429_215112_103c_3B_AnalyticMS_SR.tif for lake statistics...\n",
      "Error processing D:\\planetscope_lake_ice\\Data\\Input\\YKD\\20190429_215112_103c_3B_AnalyticMS_SR.tif: 'lake_id'\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Loop through all images to clip, clean, and classify lake ice cover (details in script above)\n",
    "\n",
    "# Loops through every study site\n",
    "for study_site in study_sites_to_process:\n",
    "\n",
    "    # Loops through every PlanetScope image in each study site folder\n",
    "    for planetscope_image_path in study_sites_to_process[study_site]:\n",
    "        try:\n",
    "            process_planetscope_image(planetscope_image_path, study_site)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {planetscope_image_path}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
